// Global reference so JS callback can update React state
let _setPredictedClass: ((label: string) => void) | null = null;
// compute convex hull (Monotone Chain)
function convexHull(points: [number, number][]): [number, number][] {
    'worklet';
    points = points.slice().sort((a, b) => a[0] - b[0] || a[1] - b[1]);
    const cross = (o: [number, number], a: [number, number], b: [number, number]) =>
        (a[0] - o[0]) * (b[1] - o[1]) - (a[1] - o[1]) * (b[0] - o[0]);
    const lower: [number, number][] = [];
    for (const p of points) {
        while (lower.length >= 2 && cross(lower[lower.length - 2], lower[lower.length - 1], p) <= 0) {
            lower.pop();
        }
        lower.push(p);
    }
    const upper: [number, number][] = [];
    for (let i = points.length - 1; i >= 0; i--) {
        const p = points[i];
        while (upper.length >= 2 && cross(upper[upper.length - 2], upper[upper.length - 1], p) <= 0) {
            upper.pop();
        }
        upper.push(p);
    }
    // Only pop if arrays have elements
    if (upper.length > 0) upper.pop();
    if (lower.length > 0) lower.pop();
    return lower.concat(upper);
}
// ray-casting point-in-polygon
function pointInPolygon(pt: [number, number], vs: [number, number][]): boolean {
    const [x, y] = pt;
    let inside = false;
    for (let i = 0, j = vs.length - 1; i < vs.length; j = i++) {
        const [xi, yi] = vs[i], [xj, yj] = vs[j];
        const intersect = ((yi > y) !== (yj > y)) &&
            (x < (xj - xi) * (y - yi) / (yj - yi) + xi);
        if (intersect) inside = !inside;
    }
    return inside;
}
import { FontAwesome5, Ionicons } from '@expo/vector-icons';
import { PaintStyle, Skia } from '@shopify/react-native-skia';
import { Buffer } from 'buffer';
import { Redirect, Stack, useFocusEffect, useRouter } from 'expo-router';
import { useCallback, useEffect, useRef, useState } from 'react';
import {
    Image,
    Pressable,
    StyleSheet,
    Text,
    View
} from 'react-native';
import email from 'react-native-email';
import {
    Camera,
    Camera as CameraLib,
    CameraPermissionStatus,
    PhotoFile,
    TakePhotoOptions,
    useCameraDevice,
    useSkiaFrameProcessor
} from 'react-native-vision-camera';
import { Worklets } from 'react-native-worklets-core';
console.log('üü¢ CameraScreen module loaded');

import { Frame, VisionCameraProxy } from 'react-native-vision-camera';
import { useResizePlugin } from 'vision-camera-resize-plugin';

export const wpLog = Worklets.createRunOnJS((tag: string, payload?: any) => {
  try {
    const msg =
      typeof payload === 'string'
        ? payload
        : JSON.stringify(payload);
    console.log(`[WP] ${tag}:`, msg);
  } catch {
    console.log(`[WP] ${tag}: <non-serializable>`);
  }
});

// JS-side callback to log Base64 wrist crop with landmark overlay

// Serialize API calls: only allow one in flight at a time
let readyToCallAPI = true;
const lineThickness = 2; // thickness in pixels for lines
const circleRadius = 4; // radius in pixels for landmark circles
const width = 256, height = 256;
const rgba = new Uint8Array(width * height * 4);
let previousGuess = "";

// Minimum time between calls in ms
// const COOLDOWN_MS = 200;
// let lastCallTime = 0;


const logWristCrop = (
    data: string | Uint8Array | any[]
) => {
    console.log('üîµ logWristCrop function entered');
    
    // Normalize to Base64 string
    let b64: string;
    try {
        if (Array.isArray(data)) {
            console.log('üîµ Converting array of', data.length, 'items');
            // Convert string numbers to actual numbers
            const numbers = data.map(str => parseInt(str, 10));
            // Create Uint8Array from numbers
            const uint8Array = new Uint8Array(numbers);
            b64 = Buffer.from(uint8Array).toString('base64');
            console.log('üîµ Successfully converted to base64, length:', b64.length);
        } else if (typeof data === 'string') {
            console.log('üîµ Data is already a string');
            b64 = data;
        } else if (data instanceof Uint8Array) {
            console.log('üîµ Converting Uint8Array');
            b64 = Buffer.from(data).toString('base64');
        } else {
            console.error('ÔøΩ Unexpected data type:', typeof data);
            return;
        }
        b64 = Buffer.from(data).toString('base64');
        console.log('üîµ Converted to base64, length:', b64.length);
    }
    if (!readyToCallAPI) {
        console.log('‚ö†Ô∏è Not ready to call API yet');
        return;
    }
    readyToCallAPI = false;
    console.log('trying');
    try {
        // Only call API if ready
        wpLog('üöÄ Calling API with wrist crop');
        fetch(
            'https://ag.usw-17.palantirfoundry.com/foundry-ml-live/api/inference/transform/ri.foundry-ml-live.main.live-deployment.3826955b-26c8-4d0c-b276-14c5738ede6b/v2',
            {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization':
                        'eyJwbG50ciI6IkxOVk1kUE5WTkxhZy8zMEVISzVzdEE9PSIsImFsZyI6IkVTMjU2In0.eyJzdWIiOiI0RS92NFRMTlJHbU9rT3c5ODlaMEp3PT0iLCJqdGkiOiJvRHRjY2FoOFFlYUhNQys1cXU4MTZ3PT0iLCJvcmciOiJaSXhWd0ZTT1E5cUhaR1lFbTQ1RU1nPT0ifQ.uMxENfVhkRur4eCIMxAgdK4EDLNdeYW9n1jqeZy1l2NMPZu079S6zrskcvDlMsfRJNQyolgAuyptAXwsi5lTbg'
                },
                body: JSON.stringify({
                    input_df: [
                        {
                            base64: b64,
                        },
                    ],
                }),
            }
        )
            .then(res => {
                console.log('‚úÖ API response status:', res.status);
                return res.json();
            })
            .then(json => {
                console.log('üìä API response JSON:', json);
                // Extract predicted_class from json.prediction array
                let predictedClass = '';
                if (json.prediction && Array.isArray(json.prediction) && json.prediction.length > 0) {
                    const entry = json.prediction[0];
                    if (entry.predicted_class != null) {
                        predictedClass = String(entry.predicted_class);
                    } else if (entry.class != null) {
                        predictedClass = String(entry.class);
                    } else if (entry.result != null) {
                        predictedClass = String(entry.result);
                    }
                } else if (typeof json === 'object' && 'predicted_class' in json) {
                    predictedClass = String((json as any).predicted_class);
                } else if (typeof json === 'string') {
                    predictedClass = json;
                }
                console.log('Predicted class:', predictedClass);
                // Call the registered setter if available
                if (_setPredictedClass) {
                    _setPredictedClass(predictedClass);
                }
                readyToCallAPI = true;
            })
            .catch(err => {
                console.error('‚ùå API request failed:', err);
                readyToCallAPI = true;
            });

        // Send email with PNG base64 string in the body
        email([], {
            subject: 'Wrist Crop PNG Base64',
            body: b64,
            checkCanOpen: false,
        }).catch((err) => {
            console.error('‚ùå Failed to open email composer:', err);
        });
    } catch (e) {
        console.error('ü•° wrist-crop PNG base64 (JS) error:', e);
    }
};

// let plugin: any = null;

/**
 * Run the ‚ÄúhandLandmarks‚Äù frame‚Äêprocessor plugin.
 *
 * @param {import('react-native-vision-camera').Frame} frame
 * @returns {Array<import('react-native-vision-camera').FrameProcessorPluginResultType>}
 */
/**
 * Initialize the frame processor plugin lazily
 */
// function initializePlugin() {
//     'worklet';
//     if (plugin === null) {
//         try {
//             const plugin = VisionCameraProxy.initFrameProcessorPlugin('handLandmarks', {});
//             console.log('HandLandmarks plugin initialized:', plugin);
//         } catch (error) {
//             console.error('Failed to initialize handLandmarks plugin:', error);
//             plugin = false; // Mark as failed
//         }
//     }
//     return plugin;
// }

// Initialize plugin
const plugin = VisionCameraProxy.initFrameProcessorPlugin('handLandmarks', {});
// console.log('üü° handLandmarks plugin instance:', plugin);

function handLandmarks(frame: Frame) {
    'worklet';

    // const pluginInstance = initializePlugin();

    // if (!pluginInstance || pluginInstance === false) {
    //     console.warn('HandLandmarks plugin not available');
    //     return [];
    // }

    // try {
    //     return pluginInstance.call(frame) || [];
    // } catch (error) {
    //     console.error('Error calling handLandmarks plugin:', error);
    //     return [];
    // }

    if (plugin == null) {
        throw new Error('Failed to load Frame Processor Plugin!');
    }
    return plugin.call(frame);
}

const lines = [
    [0, 1],
    [1, 2],
    [2, 3],
    [3, 4],
    [0, 5],
    [5, 6],
    [6, 7],
    [7, 8],
    [5, 9],
    [9, 10],
    [10, 11],
    [11, 12],
    [9, 13],
    [13, 14],
    [14, 15],
    [15, 16],
    [13, 17],
    [17, 18],
    [18, 19],
    [19, 20],
    [0, 17],
];


const CameraScreen = () => {
    const [predictedClass, setPredictedClass] = useState<string>('');
    // Register setter for external callbacks
    _setPredictedClass = setPredictedClass;
    const wristCropFrameCount = useRef(0);
    const router = useRouter();
    const [cameraPosition, setCameraPosition] = useState<'front' | 'back'>('back');
    const device = useCameraDevice(cameraPosition, {
        physicalDevices: ['ultra-wide-angle-camera'],
    });

    const { resize } = useResizePlugin();
    // console.log('üîß resize plugin:', resize);

    const [isActive, setIsActive] = useState(false);
    const [flash, setFlash] = useState<TakePhotoOptions['flash']>('off');

    const [photo, setPhoto] = useState<PhotoFile | undefined>(undefined);

    const camera = useRef<Camera>(null);

    const [cameraPermissionStatus, setCameraPermissionStatus] = useState<CameraPermissionStatus>('not-determined');
    const [microphonePermissionStatus, setMicrophonePermissionStatus] = useState<CameraPermissionStatus>('not-determined');

    const requestMicrophonePermission = async () => {
        const permission = await Camera.requestMicrophonePermission();

        setMicrophonePermissionStatus(permission);
    };

    const requestCameraPermission = async () => {
        const permission = await Camera.requestCameraPermission();

        setCameraPermissionStatus(permission);
    };

    useEffect(() => {
        (async () => {
            console.log('üîß Starting permission check');
            const camPerm = await CameraLib.getCameraPermissionStatus();
            setCameraPermissionStatus(camPerm);
            const micPerm = await CameraLib.getMicrophonePermissionStatus();
            setMicrophonePermissionStatus(micPerm);
            console.log('üé¨ Camera permission status:', camPerm, 'Microphone:', micPerm);
            requestCameraPermission();
            requestMicrophonePermission();
            console.log('Camera permission status:', camPerm);
            console.log('Microphone permission status:', micPerm);
        })();
    }, []);

    useFocusEffect(
        useCallback(() => {
            console.log('‚ñ∂Ô∏è CameraScreen gained focus, activating frame processor');
            setIsActive(true);
            return () => {
                console.log('‚è∏Ô∏è CameraScreen lost focus, deactivating frame processor');
                setIsActive(false);
            };
        }, [])
    );

    const paint = Skia.Paint();
    paint.setStyle(PaintStyle.Fill);
    paint.setStrokeWidth(2);
    paint.setColor(Skia.Color('lime'));

    const linePaint = Skia.Paint();
    linePaint.setStyle(PaintStyle.Fill);
    linePaint.setStrokeWidth(4);
    linePaint.setColor(Skia.Color('blue'));

    const logWristCropJS = Worklets.createRunOnJS((data: string | Uint8Array) => {
        console.log('üü° logWristCropJS wrapper called');
        logWristCrop(data);
        console.log('üü° logWristCropJS wrapper finished');
    });

    const frameProcessor = useSkiaFrameProcessor(frame => {
        'worklet';
        frame.render();
        try {
            wpLog('Frame processor iteration', 'Starting new frame');
            const data = handLandmarks(frame);
            const frameWidth = frame.width;
            const frameHeight = frame.height;
            const isHandArray = (d: any): d is any[][] => Array.isArray(d) && Array.isArray(d[0]);
            if (isHandArray(data)) {
                // Crop/resize frame to 256x256 RGB and draw overlays directly
                const x0 = 256;
                const y0 = 256;
                const buf = resize(frame, {
                    scale: {
                        width: 256,
                        height: 256,
                    },
                    crop: { x: 256, y: 256, width: 512, height: 512 },
                    pixelFormat: 'rgb',
                    dataType: 'uint8'
                });
                // console.log('üü¢ Frame resized to 256x256 RGB:', buf.length, 'bytes');
                // Compute (x, y) pairs as [number, number] tuples, clamped to [0, 256]
                const pts: [number, number][] = data[0].map(
                  (lm): [number, number] => {
                    const rawX = ((lm.x * frameWidth - x0) / 2);
                    const rawY = ((lm.y * frameHeight - y0) / 2);
                    // Clamp to [0, 256]
                    const xClamped = rawX < 0 ? 0 : rawX > 256 ? 256 : rawX;
                    const yClamped = rawY < 0 ? 0 : rawY > 256 ? 256 : rawY;
                    return [xClamped, yClamped];
                  }
                );
                // console.log('üü¢ Hand landmarks points:', pts);
                let hull: [number, number][] = [];
                try {
                    hull = convexHull(pts);
                    // console.log('üü¢ Convex hull points:', hull);
                } catch (hullError) {
                    console.error('üî¥ Convex hull computation error:', hullError, 'Input points:', pts);
                    throw hullError;
                }
                // Convert tuples to SkPoint objects
                let skPts;
                try {
                    skPts = hull.map(([x, y]) => ({ x, y }));
                    // console.log('üü¢ SkPoints:', skPts);
                } catch (skPtsError) {
                    console.error('üî¥ SkPoints mapping error:', skPtsError, 'Hull:', hull);
                    throw skPtsError;
                }
                let path;
                try {
                    path = Skia.Path.Make();
                    // console.log('üü¢ SkPath created:', path);
                    // Build path from SkPoint[]
                    path.addPoly(skPts, true);
                    // console.log('üü¢ Path created with points:', skPts);
                } catch (pathError) {
                    console.error('üî¥ Path creation error:', pathError, 'SkPoints:', skPts);
                    throw pathError;
                }
                // Apply mask
                try {
                    frame.drawPath(path, paint);
                    // console.log('üü¢ Path drawn on frame');
                } catch (drawPathError) {
                    console.error('üî¥ drawPath error:', drawPathError, 'Path:', path);
                    throw drawPathError;
                }
                // Draw bone lines
                try {
                    for (const [i, j] of lines) {
                        const p1 = pts[i], p2 = pts[j];
                        frame.drawLine(p1[0], p1[1], p2[0], p2[1], linePaint);
                    }
                    // console.log('üü¢ Bone lines drawn on frame');
                } catch (drawLineError) {
                    console.error('üî¥ drawLine error:', drawLineError, 'Points:', pts);
                    throw drawLineError;
                }
                // Draw landmark circles
                try {
                    for (const [x, y] of pts) {
                        frame.drawCircle(x, y, circleRadius, paint);
                    }
                    // console.log('üü¢ Landmark circles drawn on frame');
                } catch (drawCircleError) {
                    console.error('üî¥ drawCircle error:', drawCircleError, 'Points:', pts);
                    throw drawCircleError;
                }
                // Send raw RGB buffer to JS; convert there
                wristCropFrameCount.current++;
                wpLog('Frame Counter', { count: wristCropFrameCount.current, hasValidBuffer: !!buf });
                if (wristCropFrameCount.current == 75) {
                    wpLog('Frame 75 reached', { bufferLength: buf?.length });
                    if (buf) {
                        logWristCropJS(buf);
                    } else {
                        wpLog('Error', 'Buffer is null at frame 75');
                    }
                }
            }
            // Draw debug rect
            try {
                const rect = Skia.XYWHRect(256, 256, 512, 512)
                const paint1 = Skia.Paint()
                paint1.setColor(Skia.Color('red'))
                paint1.setStyle(PaintStyle.Stroke);
                frame.drawRect(rect, paint1)
            } catch (rectError) {
                console.error('üî¥ drawRect error:', rectError);
            }
        } catch (error) {
            console.error('üî¥ Frame processor error (outer):', error);
        }
    }, [resize]);

    const onTakePicturePressed = async () => {
        console.log('üì∏ onTakePicturePressed fired');
        const photo = await camera.current?.takePhoto({
            flash,
        });
        console.log('üì∏ Photo taken:', photo);
        setPhoto(photo);
    };

    if (cameraPermissionStatus === 'not-determined' || microphonePermissionStatus === 'not-determined') {
        console.log('‚è≥ Permissions loading...');
        return <Text>Loading permissions...</Text>;
    }

    if (cameraPermissionStatus !== 'granted' || microphonePermissionStatus !== 'granted') {
        console.log('üîí Permissions denied, redirecting');
        console.log('Redirecting to /permissions because permissions are not granted:', cameraPermissionStatus, microphonePermissionStatus);
        return <Redirect href="/permissions" />;
    }

    if (!device) {
        console.log('‚ùå No camera device available');
        return <Text>Camera device not found</Text>;
    }
    console.log('‚úÖ Rendering main CameraScreen UI');
    return (
        <View style={{ flex: 1 }}>
            <Stack.Screen options={{ headerShown: false }} />
            <Camera
                ref={camera}
                style={StyleSheet.absoluteFill}
                device={device}
                isActive={isActive && !photo}
                photo
                audio
                frameProcessor={frameProcessor}
                pixelFormat='rgb'
            />
            {photo && (
                <>
                    <Image source={{ uri: photo.path }} style={StyleSheet.absoluteFill} />
                    <FontAwesome5
                        onPress={() => setPhoto(undefined)}
                        name="arrow-left"
                        size={25}
                        color="white"
                        style={{ position: 'absolute', top: 50, left: 30 }}
                    />
                </>
            )}
            {!photo && (
                <>
                    <View
                        style={{
                            position: 'absolute',
                            right: 10,
                            top: 50,
                            padding: 10,
                            borderRadius: 5,
                            backgroundColor: 'rgba(0, 0, 0, 0.40)',
                            gap: 30,
                        }}
                    >
                        <Ionicons
                            name={flash === 'off' ? 'flash-off' : 'flash'}
                            onPress={() =>
                                setFlash((curValue) => (curValue === 'off' ? 'on' : 'off'))
                            }
                            size={30}
                            color="white"
                        />
                        <Ionicons
                            name="camera-reverse-outline"
                            onPress={() => setCameraPosition((p) => (p === 'back' ? 'front' : 'back'))}
                            size={30}
                            color="white"
                        />
                    </View>
                    <Pressable
                        onPress={onTakePicturePressed}
                        style={{
                            position: 'absolute',
                            alignSelf: 'center',
                            bottom: 50,
                            width: 80,
                            height: 80,
                            borderRadius: 40,
                            backgroundColor: 'white',
                            borderWidth: 4,
                            borderColor: '#eee',
                            shadowColor: '#000',
                            shadowOffset: { width: 0, height: 4 },
                            shadowOpacity: 0.3,
                            shadowRadius: 8,
                            elevation: 8,
                            justifyContent: 'center',
                            alignItems: 'center',
                        }}
                    >
                        <FontAwesome5 name="camera" size={36} color="#222" />
                    </Pressable>
                </>
            )}

            {predictedClass !== '' && (
                <View style={{
                    position: 'absolute',
                    bottom: 100,
                    alignSelf: 'center',
                    backgroundColor: 'rgba(0,0,0,0.6)',
                    paddingHorizontal: 12,
                    paddingVertical: 6,
                    borderRadius: 8,
                }}>
                    <Text style={{ color: 'white', fontSize: 18 }}>
                        {predictedClass}
                    </Text>
                </View>
            )}
        </View>
    );
};

export default CameraScreen;
